# Impact Evaluation  

## What is an impact evaluation?  
  * Assess changes in well being due to program  
  * Provides feedback to help improve design  

## But Assess chnages in what?  
  * Inputs...  
    * Human/Financial/Physical resources  
    * How many facilities do yu have?  
  * Lead to process...  
    * Program activities  
    * How well are you getting the knowledge to the public?  
  * Lead to outputs...  
    * Coverage and effective coverage  
    * How many people took advantage of your program?  
  * Finally outcomes  
    * Pop. Health, Health Expenditure, Responsiveness  
    * Important to continuously keep in mind  
    * What were the changes in health outcomes?  

## Process vs impact evaluation  
  * Process Evaluation: How well a program is being implemented, scaled up, etc  
  * Impact Evaluation: How much a program has changed a health state on a target population  

## Monitoring vs Evaluation  
  * Monitoring looks at a program as its going on  
  * Evaluation looks at outputs and end goals of program  

## Efficacy vs Impact  
  * Efficacy: Measures the intervention in a controlled setting  
  * Impact: Measures the intervention in an implementation setting  

## How do we conduct Impact Evaluation?  
  * What are we evaluating?  
    * Usually its not a drug/method but an implementation strategy  
    * Can be a single procedure or a bundle  
    * Look at incidence or survival rate  
    * Also essential to look SES covariates  
  * How  
    * Needs to be reliable and valid  
  * Attributing cause  
    * Cant just do a naive comparison  
    * You need to adjust for possible covarates effecting your outcome  
    * No selection bias, no spurious results, get some control to approximate counterfactual  
  * Ethical Considerations  
    * Phased in radomization approach  

## How Methods: Differences in Differences  
  * [Uses regression to measure differences in treatment](http://en.wikipedia.org/wiki/Difference_in_differences)
  * [Check out this paper on the JLS](https://catalyst.uw.edu/workspace/file/download/dae13cdb7d43332f36d4d37b4b56d1e6f160ef23e17639b3fd8ae1a709b4fe76?inline=1)

## How Methods: Regression Discontinuity  
  * Consider a program eligebility requirement  
    * Maybe poverty state for a conditional cash transfer  
  * We want to look at the post intervention state  

# Evaluation Project I: MPCA  

## How do you retroactively measure impact?  
  * Knowing intervention exposure is key  
    * But sometimes infeasible  
  * Data tracking should be routine  
    * Often incomplete and inconsistant  
  * Know Impact or health outcomes  
    * Sometimes you got to use proxies  

## Consider the broader health landscape  
  * Other programs being implemented  
  * SES covariates  
  * Knowledge base about epidemics  

## MCPA Objectives  
  * Reduction in all cause mortality  
  * But really look at subnational levels over time  
    * Measure disparities in access  
    * Also important for assessing impact and causality  

## Causal Attribution Analysis  
  * Its hard to isolate a program when other programs are scaled up at the same time  
  * At best you can analyze the programs as a whole  
  * You need lots of data in order to do subnational level estimates  

# Evaluation Project II: HealthRise  

## Overview  
  * Expand access of care for NCDs especially in the historically non-recieving  
  * Implemented in several India, USA, South Africa, Brazil  
  * 5 year project lasting till 2018  

## IHME's role  
  1. In Country Needs (2014-2015)  
  2. Monitor and Asses Local Projects (2015-2017)  
  3. Conduct Impact Evaluation (2017-2018)  

## Know your target group  
  * Important to know your target group and who to compare them too  
  * This may shift based on the needs of the community  

## Know the type of program  
  * Patient? Provider? Technology?
  * What is the project oriented towards  

## Comparison  
  * You want to be abel to compare all groups against each other  
  * But at the same time you need to meet the needs of the individual community  
